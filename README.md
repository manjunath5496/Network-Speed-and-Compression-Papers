<h2> Network Speed and Compression Papers </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(1).pdf" style="text-decoration:none;">Flattened Convolutional Neural Networks for Feedforward Acceleration</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(2).pdf" style="text-decoration:none;">Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(3).pdf" style="text-decoration:none;">Learning bothWeights and Connections for Efficient Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(4).pdf" style="text-decoration:none;"> Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(5).pdf" style="text-decoration:none;">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(6).pdf" style="text-decoration:none;">Stealing Machine Learning Models via Prediction APIs</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(7).pdf" style="text-decoration:none;">Pruning Convolutional Neural Networks for Resource Efficient Inference</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(8).pdf" style="text-decoration:none;"> LCNN: Lookup-based Convolutional Neural Network </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(9).pdf" style="text-decoration:none;">Trained Ternary Quantization</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(10).pdf" style="text-decoration:none;">Variational Dropout Sparsifies Deep Neural Networks </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(11).pdf" style="text-decoration:none;">Soft Weight-Sharing for Neural Network Compression</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(12).pdf" style="text-decoration:none;">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(13).pdf" style="text-decoration:none;">Bayesian Compression for Deep Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(14).pdf" style="text-decoration:none;">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(15).pdf" style="text-decoration:none;">Learning Transferable Architectures for Scalable Image Recognition</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(16).pdf" style="text-decoration:none;">Data-Free Knowledge Distillation for Deep Neural Networks</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(17).pdf" style="text-decoration:none;">CondenseNet: An Efficient DenseNet using Learned Group Convolutions</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(18).pdf" style="text-decoration:none;">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(19).pdf" style="text-decoration:none;">FD-MobileNet: Improved MobileNet with a Fast Downsampling Strategy</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(20).pdf" style="text-decoration:none;">Training wide residual networks for deployment using a single bit for each weight</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(21).pdf" style="text-decoration:none;">SqueezeNext: Hardware-Aware Neural Network Design</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(22).pdf" style="text-decoration:none;">Quantizing deep convolutional networks for efficient inference: A whitepaper</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(23).pdf" style="text-decoration:none;">Optimize Deep Convolutional Neural Network with Ternarized Weights and High Accuracy</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(24).pdf" style="text-decoration:none;">MnasNet: Platform-Aware Neural Architecture Search for Mobile</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(25).pdf" style="text-decoration:none;">MobiFace: A Lightweight Deep Learning Face Recognition on Mobile Devices</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(26).pdf" style="text-decoration:none;">ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(27).pdf" style="text-decoration:none;">Searching for MobileNetV3</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(28).pdf" style="text-decoration:none;">BlazeFace: Sub-millisecond Neural Face Detection on Mobile GPUs</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Network-Speed-and-Compression-Papers/blob/master/nes(29).pdf" style="text-decoration:none;">ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware </a></li>                              

  </ul>
